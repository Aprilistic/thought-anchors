{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VA Attention Analysis (Problem 9, Qwen3-4B)\n",
        "\n",
        "Goal: for the 10 exported rollout traces `problem_9_va_00..09`, compute VA-related attention numbers, pick the most distinctive trace, and plot early/mid/late-layer attention patterns with VA sentences highlighted.\n",
        "\n",
        "Notes:\n",
        "- This notebook uses existing whitebox utilities under `whitebox-analyses/attention_analysis/`.\n",
        "- Attention matrices are cached to disk (default: `attn_cache/`). First run will be expensive (model forward pass), subsequent runs are fast.\n",
        "- We intentionally do NOT plot all layers. We pick representative early/mid/late layers, and within each layer select the most VA-distinct head for the chosen rollout.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f94f7716",
      "metadata": {},
      "source": [
        "## Definitions (what the notebook measures)\n",
        "\n",
        "We treat `chunks.json` as the sentence units. Let there be `N` chunks (sentences).\n",
        "\n",
        "- VA mask (from `chunks_labeled.json`):\n",
        "\n",
        "  $$V_i = 1 \\;\\;\\text{iff}\\;\\; \\texttt{verbalized\\_evaluation\\_awareness} \\in \\texttt{function\\_tags}(i).$$\n",
        "\n",
        "- Attention matrix (sentence-averaged):\n",
        "\n",
        "  $$A \\in \\mathbb{R}^{N\\times N},\\; A_{ij} = \\text{avg attention from sentence } i \\to \\text{sentence } j$$\n",
        "\n",
        "- Vertical (receiver) score (as implemented by `get_vertical_scores`):\n",
        "  we mask future attention and a near-diagonal band, optionally rank-normalize per row, then for each sentence index `j` aggregate attention into `j` from sufficiently later sentences. A simplified mental model is:\n",
        "\n",
        "  $$v_j = \\operatorname{mean}_{i \\ge j + p} \\; A_{ij} \\quad (p = \\texttt{proximity\\_ignore})$$\n",
        "\n",
        "- VA distinctiveness for a single head:\n",
        "\n",
        "  $$\\Delta_{VA} = \\mathbb{E}[v_j\\mid V_j=1] - \\mathbb{E}[v_j\\mid V_j=0]$$\n",
        "\n",
        "- Rollout distinctiveness across representative layers (early/mid/late):\n",
        "\n",
        "  $$S(\\text{rollout}) = \\sum_{\\ell} \\max_h |\\Delta_{VA}(\\ell, h)|$$\n",
        "\n",
        "We select the rollout with the largest `S(rollout)` and plot the corresponding best head in each representative layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ef223002",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPO_ROOT /root/thought-anchors\n",
            "WHITEBOX_ROOT /root/thought-anchors/whitebox-analyses\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    for p in [start] + list(start.parents):\n",
        "        if (p / 'whitebox-analyses').exists():\n",
        "            return p\n",
        "    raise RuntimeError(f'Could not find repo root from {start}')\n",
        "\n",
        "REPO_ROOT = find_repo_root(Path.cwd())\n",
        "WHITEBOX_ROOT = (REPO_ROOT / 'whitebox-analyses').resolve()\n",
        "sys.path.insert(0, str(WHITEBOX_ROOT))\n",
        "print('REPO_ROOT', REPO_ROOT)\n",
        "print('WHITEBOX_ROOT', WHITEBOX_ROOT)\n",
        "\n",
        "from pytorch_models.model_config import model2layers_heads\n",
        "from attention_analysis.attn_funcs import get_avg_attention_matrix, get_vertical_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2fb356e2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODEL_NAME qwen3-4b\n",
            "N_LAYERS, N_HEADS (36, 32)\n",
            "Representative layers [3, 17, 31]\n",
            "VA_ROOT exists True\n"
          ]
        }
      ],
      "source": [
        "# --- Config ---\n",
        "MODEL_NAME = 'qwen3-4b'\n",
        "CI = 'correct_base_solution'\n",
        "\n",
        "VA_ROOT = REPO_ROOT / 'rollouts' / 'Qwen3-4B-Thinking-2507' / 'temperature_0.6_top_p_0.95' / 'va_examples'\n",
        "PROBLEM_PREFIX = 'problem_9_va_'\n",
        "\n",
        "# Cache dir for sentence-averaged attention matrices.\n",
        "# Keep this separate if you don't want to mix with other experiments.\n",
        "ATTN_CACHE_DIR = 'attn_cache'\n",
        "\n",
        "# Representative layers (early / mid / late) for Qwen3-4B (36 layers).\n",
        "N_LAYERS, N_HEADS = model2layers_heads(MODEL_NAME)\n",
        "LAYERS = [max(0, int(0.10 * (N_LAYERS - 1))), int(0.50 * (N_LAYERS - 1)), int(0.90 * (N_LAYERS - 1))]\n",
        "LAYERS = sorted(set(LAYERS))\n",
        "\n",
        "print('MODEL_NAME', MODEL_NAME)\n",
        "print('N_LAYERS, N_HEADS', (N_LAYERS, N_HEADS))\n",
        "print('Representative layers', LAYERS)\n",
        "print('VA_ROOT exists', VA_ROOT.exists())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9352c574",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10 rollout dirs\n",
            "- problem_9_va_00\n",
            "- problem_9_va_01\n",
            "- problem_9_va_02\n",
            "- problem_9_va_03\n",
            "- problem_9_va_04\n",
            "- problem_9_va_05\n",
            "- problem_9_va_06\n",
            "- problem_9_va_07\n",
            "- problem_9_va_08\n",
            "- problem_9_va_09\n"
          ]
        }
      ],
      "source": [
        "# Discover the 10 rollout examples for problem 9\n",
        "ci_dir = VA_ROOT / CI\n",
        "rollout_dirs = sorted([p for p in ci_dir.iterdir() if p.is_dir() and p.name.startswith(PROBLEM_PREFIX)])\n",
        "print('Found', len(rollout_dirs), 'rollout dirs')\n",
        "for p in rollout_dirs:\n",
        "    print('-', p.name)\n",
        "\n",
        "assert len(rollout_dirs) > 0, f'No {PROBLEM_PREFIX} dirs under {ci_dir}'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f42f372",
      "metadata": {},
      "source": [
        "## Step 0: Alignment choice (why we use chunks.json)\n",
        "\n",
        "The whitebox stack can split `base_solution.json[\"full_cot\"]` into a different number of sentences than appear in `chunks_labeled.json`.\n",
        "\n",
        "To keep indices consistent, this notebook uses:\n",
        "- sentence list = `chunks.json[\"chunks\"]`\n",
        "- text = `\\n`.join(chunks)\n",
        "- VA mask indices from `chunks_labeled.json` truncated to `len(chunks)`\n",
        "\n",
        "So: index `i` in the analysis corresponds to `chunks[i]` from `chunks.json` (before trimming)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a9ed0c8",
      "metadata": {},
      "source": [
        "## Helper functions\n",
        "We compute a per-(rollout, layer, head) distinctiveness score based on vertical attention scores:\n",
        "- `vertical_scores = get_vertical_scores(avg_attention_matrix)`\n",
        "- `delta = mean(vertical_scores[VA]) - mean(vertical_scores[nonVA])`\n",
        "\n",
        "Then we pick, for each layer, the head with max `abs(delta)` and aggregate across 3 layers to pick the most distinctive rollout.\n",
        "\n",
        "Additional descriptive matrix summaries (computed on the same attention matrix `A`):\n",
        "- Incoming into VA columns from non-VA rows:\n",
        "\n",
        "  $$\\mu_{in,VA} = \\operatorname{mean}(A_{ij} : V_i=0, V_j=1)$$\n",
        "\n",
        "- Incoming into non-VA columns from non-VA rows:\n",
        "\n",
        "  $$\\mu_{in,nonVA} = \\operatorname{mean}(A_{ij} : V_i=0, V_j=0)$$\n",
        "\n",
        "- Lift ratio (if denominator is non-zero):\n",
        "\n",
        "  $$\\text{lift}_{in} = \\mu_{in,VA} / \\mu_{in,nonVA}$$\n",
        "\n",
        "These are descriptive summaries, not causal effects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6949caec",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_chunks_and_va_mask(rollout_dir: Path):\n",
        "    chunks_path = rollout_dir / 'chunks.json'\n",
        "    labeled_path = rollout_dir / 'chunks_labeled.json'\n",
        "\n",
        "    chunks_obj = json.loads(chunks_path.read_text(encoding='utf-8'))\n",
        "    chunks = chunks_obj.get('chunks', [])\n",
        "    labeled = json.loads(labeled_path.read_text(encoding='utf-8'))\n",
        "\n",
        "    if not isinstance(chunks, list):\n",
        "        chunks = []\n",
        "    if not isinstance(labeled, list):\n",
        "        labeled = []\n",
        "\n",
        "    # We treat 'chunks' as the sentence units for attention boundaries to avoid mismatch warnings\n",
        "    # from base_solution['full_cot'] and to guarantee alignment with chunks_labeled.json.\n",
        "    n = len(chunks)\n",
        "    labeled = labeled[:n]\n",
        "\n",
        "    va_mask = np.zeros((n,), dtype=bool)\n",
        "    for i, c in enumerate(labeled):\n",
        "        tags = c.get('function_tags', []) if isinstance(c, dict) else []\n",
        "        if isinstance(tags, list) and any(t == 'verbalized_evaluation_awareness' for t in tags):\n",
        "            va_mask[i] = True\n",
        "\n",
        "    text = '\\n'.join(str(x) for x in chunks)\n",
        "    sentences = [str(x) for x in chunks]\n",
        "    return text, sentences, va_mask, labeled\n",
        "\n",
        "def safe_mean(arr: np.ndarray) -> float:\n",
        "    arr = np.asarray(arr, dtype=float)\n",
        "    if arr.size == 0:\n",
        "        return float('nan')\n",
        "    return float(np.nanmean(arr))\n",
        "\n",
        "def compute_va_stats_for_head(avg_mat: np.ndarray, va_mask: np.ndarray, proximity_ignore: int = 4):\n",
        "    n = avg_mat.shape[0]\n",
        "    assert va_mask.shape[0] == n\n",
        "    non_mask = ~va_mask\n",
        "\n",
        "    vert = get_vertical_scores(avg_mat, proximity_ignore=proximity_ignore, control_depth=True, score_type='mean')\n",
        "    va_vert = vert[va_mask]\n",
        "    non_vert = vert[non_mask]\n",
        "\n",
        "    mean_va_vert = safe_mean(va_vert)\n",
        "    mean_non_vert = safe_mean(non_vert)\n",
        "    delta_vert = mean_va_vert - mean_non_vert\n",
        "\n",
        "    # Simple matrix-based aggregates (incoming/outgoing attention).\n",
        "    # These are not causal; they are descriptive summaries.\n",
        "    mean_in_va = safe_mean(avg_mat[non_mask][:, va_mask])\n",
        "    mean_in_non = safe_mean(avg_mat[non_mask][:, non_mask])\n",
        "    mean_out_va = safe_mean(avg_mat[va_mask][:, non_mask])\n",
        "    mean_va_to_va = safe_mean(avg_mat[va_mask][:, va_mask])\n",
        "\n",
        "    lift_in = float('nan')\n",
        "    if np.isfinite(mean_in_va) and np.isfinite(mean_in_non) and mean_in_non != 0:\n",
        "        lift_in = mean_in_va / mean_in_non\n",
        "\n",
        "    return {\n",
        "        'mean_va_vert': mean_va_vert,\n",
        "        'mean_nonva_vert': mean_non_vert,\n",
        "        'delta_va_vert': delta_vert,\n",
        "        'mean_in_va': mean_in_va,\n",
        "        'mean_in_nonva': mean_in_non,\n",
        "        'lift_in_va': lift_in,\n",
        "        'mean_out_va': mean_out_va,\n",
        "        'mean_va_to_va': mean_va_to_va,\n",
        "        'vert_scores': vert,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f2be9cf",
      "metadata": {},
      "source": [
        "## Step 1: compute distinctiveness numbers across 10 rollouts\n",
        "This will trigger attention caching per rollout (expensive on first run).\n",
        "\n",
        "If you want to do a quick dry run (no model inference), set `RUN_ATTENTION = False` to only inspect VA counts.\n",
        "\n",
        "### Trimming convention\n",
        "Some legacy plotting code trims the first and last positions (`A[1:-1, 1:-1]`). This notebook applies the same trim to both the attention matrix and VA mask.\n",
        "\n",
        "Interpretation: after trimming, plotted index `k` corresponds to original chunk index `k+1` in `chunks.json`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fbff14c2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rollout_id</th>\n",
              "      <th>layer</th>\n",
              "      <th>head</th>\n",
              "      <th>n_sentences</th>\n",
              "      <th>n_va</th>\n",
              "      <th>va_rate</th>\n",
              "      <th>delta_va_vert</th>\n",
              "      <th>mean_va_vert</th>\n",
              "      <th>mean_nonva_vert</th>\n",
              "      <th>lift_in_va</th>\n",
              "      <th>mean_in_va</th>\n",
              "      <th>mean_in_nonva</th>\n",
              "      <th>mean_out_va</th>\n",
              "      <th>mean_va_to_va</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>problem_9_va_00</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>-0.365181</td>\n",
              "      <td>0.323032</td>\n",
              "      <td>0.688213</td>\n",
              "      <td>1.258111</td>\n",
              "      <td>0.002285</td>\n",
              "      <td>0.001816</td>\n",
              "      <td>0.000459</td>\n",
              "      <td>0.002595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>problem_9_va_00</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>-0.338960</td>\n",
              "      <td>0.358220</td>\n",
              "      <td>0.697181</td>\n",
              "      <td>0.598612</td>\n",
              "      <td>0.001574</td>\n",
              "      <td>0.002630</td>\n",
              "      <td>0.000531</td>\n",
              "      <td>0.006896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>problem_9_va_00</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>-0.152201</td>\n",
              "      <td>0.450563</td>\n",
              "      <td>0.602764</td>\n",
              "      <td>0.150247</td>\n",
              "      <td>0.000490</td>\n",
              "      <td>0.003260</td>\n",
              "      <td>0.000203</td>\n",
              "      <td>0.012684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>problem_9_va_00</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>-0.130446</td>\n",
              "      <td>0.460993</td>\n",
              "      <td>0.591439</td>\n",
              "      <td>0.106369</td>\n",
              "      <td>0.000351</td>\n",
              "      <td>0.003303</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.013506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>problem_9_va_00</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>-0.071155</td>\n",
              "      <td>0.449774</td>\n",
              "      <td>0.520929</td>\n",
              "      <td>0.593100</td>\n",
              "      <td>0.001234</td>\n",
              "      <td>0.002080</td>\n",
              "      <td>0.000587</td>\n",
              "      <td>0.001016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        rollout_id  layer  head  n_sentences  n_va   va_rate  delta_va_vert  \\\n",
              "0  problem_9_va_00      3     0           28     4  0.142857      -0.365181   \n",
              "1  problem_9_va_00      3     1           28     4  0.142857      -0.338960   \n",
              "2  problem_9_va_00      3     2           28     4  0.142857      -0.152201   \n",
              "3  problem_9_va_00      3     3           28     4  0.142857      -0.130446   \n",
              "4  problem_9_va_00      3     4           28     4  0.142857      -0.071155   \n",
              "\n",
              "   mean_va_vert  mean_nonva_vert  lift_in_va  mean_in_va  mean_in_nonva  \\\n",
              "0      0.323032         0.688213    1.258111    0.002285       0.001816   \n",
              "1      0.358220         0.697181    0.598612    0.001574       0.002630   \n",
              "2      0.450563         0.602764    0.150247    0.000490       0.003260   \n",
              "3      0.460993         0.591439    0.106369    0.000351       0.003303   \n",
              "4      0.449774         0.520929    0.593100    0.001234       0.002080   \n",
              "\n",
              "   mean_out_va  mean_va_to_va  \n",
              "0     0.000459       0.002595  \n",
              "1     0.000531       0.006896  \n",
              "2     0.000203       0.012684  \n",
              "3     0.000156       0.013506  \n",
              "4     0.000587       0.001016  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RUN_ATTENTION = True\n",
        "PROXIMITY_IGNORE = 4\n",
        "HEADS_TO_SCAN = list(range(N_HEADS))\n",
        "\n",
        "rows = []\n",
        "\n",
        "for rollout_dir in rollout_dirs:\n",
        "    rollout_id = rollout_dir.name\n",
        "    text, sentences, va_mask, labeled = load_chunks_and_va_mask(rollout_dir)\n",
        "    n_sent = len(sentences)\n",
        "    n_va = int(va_mask.sum())\n",
        "\n",
        "    if not RUN_ATTENTION:\n",
        "        rows.append({\n",
        "            'rollout_id': rollout_id,\n",
        "            'n_sentences': n_sent,\n",
        "            'n_va': n_va,\n",
        "            'va_rate': (n_va / n_sent) if n_sent else float('nan'),\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    # First call triggers cache for all layers/heads for this text_id (fast afterwards).\n",
        "    _ = get_avg_attention_matrix(\n",
        "        text=text,\n",
        "        model_name=MODEL_NAME,\n",
        "        layer=LAYERS[0],\n",
        "        head=0,\n",
        "        sentences=sentences,\n",
        "        cache_dir=ATTN_CACHE_DIR,\n",
        "        force_recompute=False,\n",
        "    )\n",
        "\n",
        "    for layer in LAYERS:\n",
        "        for head in HEADS_TO_SCAN:\n",
        "            avg_mat = get_avg_attention_matrix(\n",
        "                text=text,\n",
        "                model_name=MODEL_NAME,\n",
        "                layer=layer,\n",
        "                head=head,\n",
        "                sentences=sentences,\n",
        "                cache_dir=ATTN_CACHE_DIR,\n",
        "                force_recompute=False,\n",
        "            )\n",
        "\n",
        "            # Keep consistent with plot_one_attn_matrix.py which trims prompt/output bins in legacy runs.\n",
        "            if avg_mat.shape[0] >= 3:\n",
        "                avg_mat2 = avg_mat[1:-1, 1:-1]\n",
        "                va_mask2 = va_mask[1:-1]\n",
        "            else:\n",
        "                avg_mat2 = avg_mat\n",
        "                va_mask2 = va_mask\n",
        "\n",
        "            stats = compute_va_stats_for_head(avg_mat2, va_mask2, proximity_ignore=PROXIMITY_IGNORE)\n",
        "\n",
        "            rows.append({\n",
        "                'rollout_id': rollout_id,\n",
        "                'layer': int(layer),\n",
        "                'head': int(head),\n",
        "                'n_sentences': int(avg_mat2.shape[0]),\n",
        "                'n_va': int(va_mask2.sum()),\n",
        "                'va_rate': float(va_mask2.sum() / max(1, avg_mat2.shape[0])),\n",
        "                'delta_va_vert': stats['delta_va_vert'],\n",
        "                'mean_va_vert': stats['mean_va_vert'],\n",
        "                'mean_nonva_vert': stats['mean_nonva_vert'],\n",
        "                'lift_in_va': stats['lift_in_va'],\n",
        "                'mean_in_va': stats['mean_in_va'],\n",
        "                'mean_in_nonva': stats['mean_in_nonva'],\n",
        "                'mean_out_va': stats['mean_out_va'],\n",
        "                'mean_va_to_va': stats['mean_va_to_va'],\n",
        "            })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ff8e0a6b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rollout_id</th>\n",
              "      <th>distinctiveness_score</th>\n",
              "      <th>n_va</th>\n",
              "      <th>n_sentences</th>\n",
              "      <th>va_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>problem_9_va_07</td>\n",
              "      <td>1.385077</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.095238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>problem_9_va_03</td>\n",
              "      <td>1.204702</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>0.153846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>problem_9_va_08</td>\n",
              "      <td>1.151686</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>problem_9_va_00</td>\n",
              "      <td>1.084855</td>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>problem_9_va_04</td>\n",
              "      <td>1.057501</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>0.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>problem_9_va_02</td>\n",
              "      <td>0.964348</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>0.130435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>problem_9_va_09</td>\n",
              "      <td>0.952159</td>\n",
              "      <td>3</td>\n",
              "      <td>26</td>\n",
              "      <td>0.115385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>problem_9_va_06</td>\n",
              "      <td>0.791427</td>\n",
              "      <td>4</td>\n",
              "      <td>35</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>problem_9_va_05</td>\n",
              "      <td>0.782347</td>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>problem_9_va_01</td>\n",
              "      <td>0.612222</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>0.185185</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        rollout_id  distinctiveness_score  n_va  n_sentences   va_rate\n",
              "7  problem_9_va_07               1.385077     2           21  0.095238\n",
              "3  problem_9_va_03               1.204702     4           26  0.153846\n",
              "8  problem_9_va_08               1.151686     2           22  0.090909\n",
              "0  problem_9_va_00               1.084855     4           28  0.142857\n",
              "4  problem_9_va_04               1.057501     4           32  0.125000\n",
              "2  problem_9_va_02               0.964348     3           23  0.130435\n",
              "9  problem_9_va_09               0.952159     3           26  0.115385\n",
              "6  problem_9_va_06               0.791427     4           35  0.114286\n",
              "5  problem_9_va_05               0.782347     4           36  0.111111\n",
              "1  problem_9_va_01               0.612222     5           27  0.185185"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best rollout by distinctiveness: problem_9_va_07\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>layer</th>\n",
              "      <th>head</th>\n",
              "      <th>delta_va_vert</th>\n",
              "      <th>lift_in_va</th>\n",
              "      <th>n_va</th>\n",
              "      <th>n_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.475174</td>\n",
              "      <td>0.391993</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>17</td>\n",
              "      <td>10</td>\n",
              "      <td>-0.461536</td>\n",
              "      <td>0.911328</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.448367</td>\n",
              "      <td>2.697211</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    layer  head  delta_va_vert  lift_in_va  n_va  n_sentences\n",
              "21      3     1      -0.475174    0.391993     2           21\n",
              "22     17    10      -0.461536    0.911328     2           21\n",
              "23     31     0       0.448367    2.697211     2           21"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if not RUN_ATTENTION:\n",
        "    display(df.sort_values(['n_va', 'n_sentences'], ascending=[False, False]))\n",
        "else:\n",
        "    # Pick the most VA-distinct head per layer per rollout (max abs delta).\n",
        "    df['abs_delta_va_vert'] = df['delta_va_vert'].abs()\n",
        "    best_per_layer = (\n",
        "        df.sort_values('abs_delta_va_vert', ascending=False)\n",
        "          .groupby(['rollout_id', 'layer'], as_index=False)\n",
        "          .first()\n",
        "    )\n",
        "\n",
        "    # Aggregate distinctiveness across the representative layers.\n",
        "    agg = (\n",
        "        best_per_layer.groupby('rollout_id')\n",
        "        .agg({\n",
        "            'abs_delta_va_vert': 'sum',\n",
        "            'n_va': 'first',\n",
        "            'n_sentences': 'first',\n",
        "        })\n",
        "        .rename(columns={'abs_delta_va_vert': 'distinctiveness_score'})\n",
        "        .reset_index()\n",
        "    )\n",
        "    agg['va_rate'] = agg['n_va'] / agg['n_sentences'].clip(lower=1)\n",
        "\n",
        "    display(agg.sort_values('distinctiveness_score', ascending=False))\n",
        "\n",
        "    best_rollout_id = agg.sort_values('distinctiveness_score', ascending=False).iloc[0]['rollout_id']\n",
        "    print('Best rollout by distinctiveness:', best_rollout_id)\n",
        "\n",
        "    best_heads = best_per_layer[best_per_layer['rollout_id'] == best_rollout_id].sort_values('layer')\n",
        "    display(best_heads[['layer', 'head', 'delta_va_vert', 'lift_in_va', 'n_va', 'n_sentences']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70c1b502",
      "metadata": {},
      "source": [
        "## Step 1b: pick the most distinctive rollout (formula recap)\n",
        "\n",
        "For each rollout and each representative layer `\\ell`, we choose the head `h` that maximizes `|\\Delta_{VA}(\\ell,h)|`.\n",
        "Then we sum these maxima across the three layers:\n",
        "\n",
        "$$S(\\text{rollout}) = \\sum_{\\ell} \\max_h |\\Delta_{VA}(\\ell, h)|$$\n",
        "\n",
        "This is deliberately a *find a strong separation* score. It is meant to select an illustrative example, not to estimate an average effect across heads."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce381558",
      "metadata": {},
      "source": [
        "## Step 2: Plot early/mid/late attention matrices for the most distinctive rollout\n",
        "We replicate the core idea of `plot_one_attn_matrix.py` but inline here so we can target `problem_9_va_XX` directories directly and produce multiple plots in one notebook cell.\n",
        "\n",
        "### How to read the heatmap\n",
        "- Rows = source sentence index `i`\n",
        "- Cols = target sentence index `j`\n",
        "- Color = `A_{ij}` (average attention from sentence `i` to sentence `j`)\n",
        "- Red overlays mark VA sentences (both rows and columns are highlighted)\n",
        "\n",
        "### How to read the vertical-score plot\n",
        "- The vertical score is a receiver/sink metric computed from `A` (see Definitions at top).\n",
        "- Red points are VA sentences; gray points are non-VA sentences.\n",
        "- If the red points tend to be higher, you should see a positive `delta_va_vert`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "bf02e24a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def overlay_va_highlights(ax, va_mask, axis='both', color='red', alpha=0.18):\n",
        "    axis = (axis or 'both').lower()\n",
        "    for idx, is_hit in enumerate(va_mask):\n",
        "        if not is_hit:\n",
        "            continue\n",
        "        if axis in ('rows', 'both'):\n",
        "            ax.axhspan(idx - 0.5, idx + 0.5, color=color, alpha=alpha, linewidth=0)\n",
        "        if axis in ('cols', 'both'):\n",
        "            ax.axvspan(idx - 0.5, idx + 0.5, color=color, alpha=alpha, linewidth=0)\n",
        "\n",
        "def plot_attn_heatmap(avg_mat, va_mask, title, save_path=None, show=True):\n",
        "    # Use a robust vmax based on lower triangle to avoid being dominated by outliers.\n",
        "    tril = np.tril(avg_mat)\n",
        "    vmax = float(np.nanquantile(tril, 0.99)) if np.isfinite(tril).any() else 1.0\n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    im = ax.imshow(avg_mat, vmin=0, vmax=vmax, cmap=plt.cm.Blues)\n",
        "    overlay_va_highlights(ax, va_mask, axis='both', color='red', alpha=0.18)\n",
        "    ax.set_title(title, fontsize=11)\n",
        "    ax.set_xlabel('Sentence position')\n",
        "    ax.set_ylabel('Sentence position')\n",
        "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "    plt.tight_layout()\n",
        "    if save_path is not None:\n",
        "        save_path = Path(save_path)\n",
        "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        fig.savefig(save_path, dpi=250)\n",
        "    if show:\n",
        "        plt.show()\n",
        "    plt.close(fig)\n",
        "\n",
        "def plot_vertical_scores(vert_scores, va_mask, title, save_path=None, show=True):\n",
        "    x = np.arange(len(vert_scores))\n",
        "    fig, ax = plt.subplots(figsize=(10, 2.5))\n",
        "    ax.plot(x, vert_scores, color='#0f172a', linewidth=1)\n",
        "    ax.scatter(x[~va_mask], np.asarray(vert_scores)[~va_mask], s=12, color='#94a3b8', alpha=0.8, label='non-VA')\n",
        "    ax.scatter(x[va_mask], np.asarray(vert_scores)[va_mask], s=24, color='#ef4444', alpha=0.95, label='VA')\n",
        "    ax.set_title(title, fontsize=11)\n",
        "    ax.set_xlabel('Sentence idx')\n",
        "    ax.set_ylabel('Vertical score')\n",
        "    ax.legend(loc='upper right')\n",
        "    plt.tight_layout()\n",
        "    if save_path is not None:\n",
        "        save_path = Path(save_path)\n",
        "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        fig.savefig(save_path, dpi=250)\n",
        "    if show:\n",
        "        plt.show()\n",
        "    plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "8f50033d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving plots under /root/thought-anchors/analysis/va_attention/problem_9\n",
            "Done saving all rollout plots.\n"
          ]
        }
      ],
      "source": [
        "assert RUN_ATTENTION, 'Set RUN_ATTENTION=True to generate attention plots.'\n",
        "\n",
        "# Save plots for *all* rollouts, not only the best one.\n",
        "OUTPUT_DIR = REPO_ROOT / 'analysis' / 'va_attention' / 'problem_9'\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print('Saving plots under', OUTPUT_DIR)\n",
        "\n",
        "best_per_layer_by_rollout = (\n",
        "    df.assign(abs_delta_va_vert=df['delta_va_vert'].abs())\n",
        "      .sort_values('abs_delta_va_vert', ascending=False)\n",
        "      .groupby(['rollout_id', 'layer'], as_index=False)\n",
        "      .first()\n",
        ")\n",
        "\n",
        "# Collect per-rollout numeric summaries while saving plots\n",
        "summary_rows = []\n",
        "\n",
        "for rollout_dir in rollout_dirs:\n",
        "    rollout_id = rollout_dir.name\n",
        "    text, sentences, va_mask, labeled = load_chunks_and_va_mask(rollout_dir)\n",
        "\n",
        "    per_layer = best_per_layer_by_rollout[best_per_layer_by_rollout['rollout_id'] == rollout_id].sort_values('layer')\n",
        "    if per_layer.empty:\n",
        "        print('Skip (no per-layer selection):', rollout_id)\n",
        "        continue\n",
        "\n",
        "    rollout_out = OUTPUT_DIR / rollout_id\n",
        "    rollout_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    meta = {\n",
        "        'rollout_id': rollout_id,\n",
        "        'n_sentences': int(len(sentences)),\n",
        "        'n_va': int(va_mask.sum()),\n",
        "        'va_idxs': [int(i) for i, v in enumerate(va_mask.tolist()) if v],\n",
        "        'layers': [int(x) for x in per_layer['layer'].tolist()],\n",
        "        'heads': [int(x) for x in per_layer['head'].tolist()],\n",
        "    }\n",
        "    (rollout_out / 'meta.json').write_text(json.dumps(meta, indent=2), encoding='utf-8')\n",
        "\n",
        "    sel = per_layer.copy()\n",
        "    sel['abs_delta_va_vert'] = sel['delta_va_vert'].abs()\n",
        "    distinctiveness_score = float(sel['abs_delta_va_vert'].sum())\n",
        "\n",
        "    summary_rows.append({\n",
        "        'rollout_id': rollout_id,\n",
        "        'n_sentences': int(len(sentences)),\n",
        "        'n_va': int(va_mask.sum()),\n",
        "        'va_rate': float(va_mask.sum() / max(1, len(sentences))),\n",
        "        'distinctiveness_score': distinctiveness_score,\n",
        "        'layers': ','.join(str(int(x)) for x in sel['layer'].tolist()),\n",
        "        'heads': ','.join(str(int(x)) for x in sel['head'].tolist()),\n",
        "        'delta_va_vert_by_layer': ','.join(f\"{float(x):.4f}\" for x in sel['delta_va_vert'].tolist()),\n",
        "        'lift_in_va_by_layer': ','.join(\n",
        "            f\"{float(x):.3f}\" if np.isfinite(float(x)) else 'nan'\n",
        "            for x in sel['lift_in_va'].tolist()\n",
        "        ),\n",
        "    })\n",
        "\n",
        "    for _, row in per_layer.iterrows():\n",
        "        layer = int(row['layer'])\n",
        "        head = int(row['head'])\n",
        "\n",
        "        avg_mat = get_avg_attention_matrix(\n",
        "            text=text,\n",
        "            model_name=MODEL_NAME,\n",
        "            layer=layer,\n",
        "            head=head,\n",
        "            sentences=sentences,\n",
        "            cache_dir=ATTN_CACHE_DIR,\n",
        "            force_recompute=False,\n",
        "        )\n",
        "\n",
        "        if avg_mat.shape[0] >= 3:\n",
        "            avg_mat2 = avg_mat[1:-1, 1:-1]\n",
        "            va_mask2 = va_mask[1:-1]\n",
        "        else:\n",
        "            avg_mat2 = avg_mat\n",
        "            va_mask2 = va_mask\n",
        "\n",
        "        stats = compute_va_stats_for_head(avg_mat2, va_mask2, proximity_ignore=PROXIMITY_IGNORE)\n",
        "\n",
        "        title = f\"{rollout_id} | layer={layer} head={head} | delta_va_vert={stats['delta_va_vert']:.4f} lift_in_va={stats['lift_in_va']:.3f}\"\n",
        "        heat_fp = rollout_out / f'attn_layer{layer:02d}_head{head:02d}.png'\n",
        "        vert_fp = rollout_out / f'vert_layer{layer:02d}_head{head:02d}.png'\n",
        "\n",
        "        plot_attn_heatmap(avg_mat2, va_mask2, title, save_path=heat_fp, show=False)\n",
        "        plot_vertical_scores(stats['vert_scores'], va_mask2, f\"Vertical scores | {rollout_id} | layer={layer} head={head}\", save_path=vert_fp, show=False)\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows).sort_values('distinctiveness_score', ascending=False)\n",
        "display(summary_df)\n",
        "summary_df.to_csv(OUTPUT_DIR / 'summary.csv', index=False)\n",
        "print('Wrote', OUTPUT_DIR / 'summary.csv')\n",
        "print('Done saving all rollout plots.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eb7c1dd",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
